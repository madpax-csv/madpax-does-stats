[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "madpaxdoesstats",
    "section": "",
    "text": "Tutorial\n\n\n\n\n\n\nresearch\n\n\n\n\n\n\n\n\n\nMay 2, 2025\n\n\nMaddy Paxson\n\n\n\n\n\n\n\n\n\n\n\n\nPost With Code\n\n\n\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\nFeb 9, 2025\n\n\nHarlow Malloc\n\n\n\n\n\n\n\n\n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\nFeb 6, 2025\n\n\nTristan O’Malley\n\n\n\n\n\n\n\n\n\n\n\n\nI know how to use a Quarto Blog\n\n\n\n\n\n\nresearch\n\n\n\n\n\n\n\n\n\nFeb 6, 2025\n\n\nMaddy Paxson\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/My first post/index.html",
    "href": "posts/My first post/index.html",
    "title": "I know how to use a Quarto Blog",
    "section": "",
    "text": "This is my blog post! Here’s a picture, too."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About madpaxdoesstats",
    "section": "",
    "text": "More about this blog coming soon."
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "This is a post with executable code.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "posts/Tutorial/tut_index.html",
    "href": "posts/Tutorial/tut_index.html",
    "title": "Tutorial",
    "section": "",
    "text": "Hi, welcome to my first tutorial!\nToday, we’re going to be trying to understand how friendships change during the transition to college.\nBut first, let’s load and install all of the packages we’ll need. Run the code below to install packages you may not already have.\n\n\n\n#List of packages we'll use. \n\npackages &lt;- c(\"tidyverse\",\"dplyr\", \"lme4\", \"ggplot2\", \"readr\",\"naniar\",\"nortest\")  \n#Identifies which packages you already have\ninstall_if_missing &lt;- setdiff(packages, rownames(installed.packages()))\n#Installs packages you don't have\nif (length(install_if_missing)) install.packages(install_if_missing)\n#Calls all needed packages \nlapply(packages, library, character.only = TRUE)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\nLoading required package: Matrix\n\n\nAttaching package: 'Matrix'\n\n\nThe following objects are masked from 'package:tidyr':\n\n    expand, pack, unpack\n\n\n[[1]]\n [1] \"lubridate\" \"forcats\"   \"stringr\"   \"dplyr\"     \"purrr\"     \"readr\"    \n [7] \"tidyr\"     \"tibble\"    \"ggplot2\"   \"tidyverse\" \"stats\"     \"graphics\" \n[13] \"grDevices\" \"utils\"     \"datasets\"  \"methods\"   \"base\"     \n\n[[2]]\n [1] \"lubridate\" \"forcats\"   \"stringr\"   \"dplyr\"     \"purrr\"     \"readr\"    \n [7] \"tidyr\"     \"tibble\"    \"ggplot2\"   \"tidyverse\" \"stats\"     \"graphics\" \n[13] \"grDevices\" \"utils\"     \"datasets\"  \"methods\"   \"base\"     \n\n[[3]]\n [1] \"lme4\"      \"Matrix\"    \"lubridate\" \"forcats\"   \"stringr\"   \"dplyr\"    \n [7] \"purrr\"     \"readr\"     \"tidyr\"     \"tibble\"    \"ggplot2\"   \"tidyverse\"\n[13] \"stats\"     \"graphics\"  \"grDevices\" \"utils\"     \"datasets\"  \"methods\"  \n[19] \"base\"     \n\n[[4]]\n [1] \"lme4\"      \"Matrix\"    \"lubridate\" \"forcats\"   \"stringr\"   \"dplyr\"    \n [7] \"purrr\"     \"readr\"     \"tidyr\"     \"tibble\"    \"ggplot2\"   \"tidyverse\"\n[13] \"stats\"     \"graphics\"  \"grDevices\" \"utils\"     \"datasets\"  \"methods\"  \n[19] \"base\"     \n\n[[5]]\n [1] \"lme4\"      \"Matrix\"    \"lubridate\" \"forcats\"   \"stringr\"   \"dplyr\"    \n [7] \"purrr\"     \"readr\"     \"tidyr\"     \"tibble\"    \"ggplot2\"   \"tidyverse\"\n[13] \"stats\"     \"graphics\"  \"grDevices\" \"utils\"     \"datasets\"  \"methods\"  \n[19] \"base\"     \n\n[[6]]\n [1] \"naniar\"    \"lme4\"      \"Matrix\"    \"lubridate\" \"forcats\"   \"stringr\"  \n [7] \"dplyr\"     \"purrr\"     \"readr\"     \"tidyr\"     \"tibble\"    \"ggplot2\"  \n[13] \"tidyverse\" \"stats\"     \"graphics\"  \"grDevices\" \"utils\"     \"datasets\" \n[19] \"methods\"   \"base\"     \n\n[[7]]\n [1] \"nortest\"   \"naniar\"    \"lme4\"      \"Matrix\"    \"lubridate\" \"forcats\"  \n [7] \"stringr\"   \"dplyr\"     \"purrr\"     \"readr\"     \"tidyr\"     \"tibble\"   \n[13] \"ggplot2\"   \"tidyverse\" \"stats\"     \"graphics\"  \"grDevices\" \"utils\"    \n[19] \"datasets\"  \"methods\"   \"base\"     \n\n\nGreat! Now let’s load our data from GitHub.\n\nurl &lt;- \"https://raw.githubusercontent.com/madpax-csv/madpax-does-stats/refs/heads/master/wNAs_FourWaves_FTlevel.csv\"\nFFH &lt;- read_csv(url)\n\nWarning: One or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\n\n\nRows: 8064 Columns: 169\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr   (6): gender_FR, race_FR, distance_mi_cats, race_cat, H_FriendID_, Time\ndbl (157): ID, over18, inFSI, age, gender, transgender, international, frien...\nnum   (3): race, selectHomeFriend, listPton\nlgl   (3): loneliness, winterPlan, composite_Lon_Men\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n#You may get an error about parsing issues, but it looks normal to me... \n\nExplain dataset.\nThe Adversity and Close Relationships Lab surveyed students about their friendships at four different time points throughout their first year of college.\nIn the summer (Intake) before they moved on campus, we asked them to list up to 7 current friends and how close they are to each friend, how long they’ve been friends, and whether this friend is in college.\nThen, in the Fall, Winter, and Spring, we asked if they still consider this person a friend. If they do, we then ask about how close they are to that friend now. (We do not ask about length of friendship or college enrollment for these friends again.)\nWe are using a few key variables:\n\nID: This is a given surveyed participants’ unique ID number.\nTime: This refers to the time point at which responses were given (i.e., Intake, Fall, Winter, Spring).\nH_FriendID_: This is a unique ID for each friend that a participant listed.\nH_closeFriend: This refers to how close a participant rated a friend at a given timepoint.\n\n1 = Not At All Close; 5 = Extremely Close\n\n\nWe may also look at a few controls and moderators, which I will include in our dataset for now, and will explain later when we come to it.\nBefore we dive in, let’s widdle down our dataset FFH (friends from home) to make it easier to explore. We’ll also quickly ensure the data types are appropriate.\n\nFFH &lt;- FFH %&gt;%\n  select(\n    #Main variables of interest\n    ID, Time, H_FriendID_, H_closeFriend,\n    #Potential Moderators\n    H_Friend_college,\n    #For Filtering\n    H_friend_in_Net) %&gt;%\n  mutate(\n    ID = as.character(ID),\n    Time = factor(Time, levels = c(\"Intake\", \"Fall\", \"Winter\", \"Spring\")),\n    H_FriendID_ = as.character(H_FriendID_),\n    H_closeFriend = as.numeric(H_closeFriend),\n    H_Friend_college = factor(H_Friend_college, levels = c(0, 1))  )\nFFH &lt;- FFH %&gt;%\n  select(ID, H_FriendID_, everything())\n\nWalk through dataset and its structure.\nOur data is at the Friend/Time level. This means that each row represents how our participant thought of a friend at a given timepoint.\nBelow, you can print an example of how one participant responded about one friend at each timepoint. Notice how the ID and the Friend ID are both the same in each row, but the time point differs.\n\nstructure_ex &lt;- FFH %&gt;%\n  filter(ID == \"211810\" & H_FriendID_ == \"1\")\n  \nprint(structure_ex)\n\n# A tibble: 4 × 6\n  ID     H_FriendID_ Time   H_closeFriend H_Friend_college H_friend_in_Net\n  &lt;chr&gt;  &lt;chr&gt;       &lt;fct&gt;          &lt;dbl&gt; &lt;fct&gt;                      &lt;dbl&gt;\n1 211810 1           Intake             5 1                              1\n2 211810 1           Fall               5 1                              1\n3 211810 1           Winter             3 1                              1\n4 211810 1           Spring             4 1                              1\n\n\nLet’s look at all of the friends this participant listed to better understand the structure of the data.\nYou’ll notice that each Participant (ID) has at least one friend (H_FriendID_) and for each friend, there is a time point (Time). In other words…\nParticipant (ID) → Friend (H_FriendID_) → Time point (Time)\nLevel 1: Repeated measurements (e.g., closeness over time)\nLevel 2: Friend-level variables (e.g., how long they’ve known each friend)\nLevel 3: Participant-level variables (e.g., age, inFSI)\n\nstructure_ex2 &lt;- FFH %&gt;%\n  filter(ID == \"211810\")\n  \nprint(structure_ex2)\n\n# A tibble: 28 × 6\n   ID     H_FriendID_ Time   H_closeFriend H_Friend_college H_friend_in_Net\n   &lt;chr&gt;  &lt;chr&gt;       &lt;fct&gt;          &lt;dbl&gt; &lt;fct&gt;                      &lt;dbl&gt;\n 1 211810 1           Intake             5 1                              1\n 2 211810 1           Fall               5 1                              1\n 3 211810 1           Winter             3 1                              1\n 4 211810 1           Spring             4 1                              1\n 5 211810 320         Intake             5 1                              1\n 6 211810 320         Fall               5 1                              1\n 7 211810 320         Winter             5 1                              1\n 8 211810 320         Spring             4 1                              1\n 9 211810 634         Intake             4 1                              1\n10 211810 634         Fall               3 1                              1\n# ℹ 18 more rows\n\n\nLet’s take a glimpse at our data.\n\nglimpse(FFH)\n\nRows: 8,064\nColumns: 6\n$ ID               &lt;chr&gt; \"211810\", \"211810\", \"211810\", \"211810\", \"211810\", \"21…\n$ H_FriendID_      &lt;chr&gt; \"1\", \"1\", \"1\", \"1\", \"320\", \"320\", \"320\", \"320\", \"634\"…\n$ Time             &lt;fct&gt; Intake, Fall, Winter, Spring, Intake, Fall, Winter, S…\n$ H_closeFriend    &lt;dbl&gt; 5, 5, 3, 4, 5, 5, 5, 4, 4, 3, NA, NA, 3, 3, NA, NA, N…\n$ H_Friend_college &lt;fct&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, NA, N…\n$ H_friend_in_Net  &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, NA, N…\n\ngg_miss_var(FFH)\n\n\n\n\n\n\n\n\nYou might notice that while we have very few missing values for participant-level variables like age, there are many more missing values for friend-related variables. These missing values arise for two main reasons:\n\nNot all participants listed 7 friends during the Intake survey—some listed fewer, leaving empty friend slots for information about closeness etc.\nNot all friends were still considered friends at each time point (Fall, Winter, Spring), so their closeness ratings are missing for those waves\n\nLet’s address each of these points. Luckily, in another file, our data has already noted when a participant hasn’t listed someone in a given slot. So we are going to remove those slots where no one was listed. Let’s see the effect that this had.\nWe can see that those questions that were ONLY asked in Intake are now only missing for 5 participants – and we can assume that 5 people skipped one of those questions.\n\nFFH &lt;- FFH %&gt;%\n  filter(H_FriendID_ != \"none listed\")\ngg_miss_var(FFH)\n\n\n\n\n\n\n\nwhy &lt;- FFH %&gt;%\n  filter(is.na(H_Friend_college))\nn_distinct(why$ID)\n\n[1] 5\n\n\nWhen a person listed as a friend at Intake is no longer named in Fall, Winter, or Spring, their closeness rating is left missing by default. However, this missingness is meaningful—it reflects the potential loss of a friendship, which is theoretically important. Rather than removing these cases, we recode their missing closeness values to 1, representing “Not at all close” on our scale. This allows us to retain these friends in the dataset and interpret their absence as a signal of relationship deterioration.\n\nFFH &lt;- FFH %&gt;%\n  mutate(H_closeFriend = if_else(H_friend_in_Net == 0, 1, H_closeFriend))\n\nAt this stage, any remaining missing values reflect questions that participants skipped. For simplicity, we’ll remove those cases. (Not really the main point of this tutorial)\n\nFFH &lt;- FFH %&gt;%\n  drop_na()\n\nLet’s take a quick look at more information about our data.\n\nn_participants &lt;- n_distinct(FFH$ID)\nprint(paste(\"Number of unique participants:\", n_participants))\n\n[1] \"Number of unique participants: 283\"\n\nn_friends &lt;- n_distinct(FFH$H_FriendID_)\nprint(paste(\"Number of unique friends listed:\", n_friends))\n\n[1] \"Number of unique friends listed: 1594\"\n\nFFH %&gt;%\n  ggplot(aes(x = H_closeFriend)) +\n  geom_histogram(binwidth = 1, fill = \"steelblue\", color = \"white\", boundary = 0) +\n  facet_wrap(~Time) +\n  labs(title = \"Histogram of Closeness by Timepoint\",\n       x = \"Closeness (1 = Not at all close, 5 = Extremely close)\",\n       y = \"Count\") +\n  theme_minimal() +\n  theme(panel.grid = element_blank())\n\n\n\n\n\n\n\nlillie.test(FFH$H_closeFriend)\n\n\n    Lilliefors (Kolmogorov-Smirnov) normality test\n\ndata:  FFH$H_closeFriend\nD = 0.19051, p-value &lt; 2.2e-16\n\n\nSo, we have 288 participants and 1,617 unique friends listed. In the table, you’ll see a breakdown of closeness at each time point. These histograms, plus a quick test of normality, show that our outcome is not normally distributed. But, it’s worth making our model and then investigating once the model is set.\nNow that we know what we’re working with, we can start to decipher a model to investigate our research question:\nWhat is the effect of Time on Closeness to friends from home?\nBecause of the nested nature of this data, our biggest contender is a mixed linear regression.\nA mixed linear model (also called a multilevel or hierarchical linear model) is a type of regression that accounts for nested or grouped data.\nIn our case, closeness ratings are repeated over time within each friend, and each friend is nested within a participant. This violates the assumption of independence in traditional linear regression, because observations from the same person or the same friendship are likely to be more similar to each other than to those from others. A mixed linear regression is ideal here because it allows us to model both fixed effects (like time) and random effects (like variation across participants and friendships). This helps us better understand the average trends while also accounting for individual differences in how close someone feels to their friends in general.\nBut first, we need to check a few assumptions to make sure this is the right model for us."
  },
  {
    "objectID": "posts/Tutorial/tut_index.html#install-and-load-packages",
    "href": "posts/Tutorial/tut_index.html#install-and-load-packages",
    "title": "Tutorial",
    "section": "",
    "text": "#List of packages we'll use. \n\npackages &lt;- c(\"tidyverse\",\"dplyr\", \"lme4\", \"ggplot2\", \"readr\",\"naniar\",\"nortest\")  \n#Identifies which packages you already have\ninstall_if_missing &lt;- setdiff(packages, rownames(installed.packages()))\n#Installs packages you don't have\nif (length(install_if_missing)) install.packages(install_if_missing)\n#Calls all needed packages \nlapply(packages, library, character.only = TRUE)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\nLoading required package: Matrix\n\n\nAttaching package: 'Matrix'\n\n\nThe following objects are masked from 'package:tidyr':\n\n    expand, pack, unpack\n\n\n[[1]]\n [1] \"lubridate\" \"forcats\"   \"stringr\"   \"dplyr\"     \"purrr\"     \"readr\"    \n [7] \"tidyr\"     \"tibble\"    \"ggplot2\"   \"tidyverse\" \"stats\"     \"graphics\" \n[13] \"grDevices\" \"utils\"     \"datasets\"  \"methods\"   \"base\"     \n\n[[2]]\n [1] \"lubridate\" \"forcats\"   \"stringr\"   \"dplyr\"     \"purrr\"     \"readr\"    \n [7] \"tidyr\"     \"tibble\"    \"ggplot2\"   \"tidyverse\" \"stats\"     \"graphics\" \n[13] \"grDevices\" \"utils\"     \"datasets\"  \"methods\"   \"base\"     \n\n[[3]]\n [1] \"lme4\"      \"Matrix\"    \"lubridate\" \"forcats\"   \"stringr\"   \"dplyr\"    \n [7] \"purrr\"     \"readr\"     \"tidyr\"     \"tibble\"    \"ggplot2\"   \"tidyverse\"\n[13] \"stats\"     \"graphics\"  \"grDevices\" \"utils\"     \"datasets\"  \"methods\"  \n[19] \"base\"     \n\n[[4]]\n [1] \"lme4\"      \"Matrix\"    \"lubridate\" \"forcats\"   \"stringr\"   \"dplyr\"    \n [7] \"purrr\"     \"readr\"     \"tidyr\"     \"tibble\"    \"ggplot2\"   \"tidyverse\"\n[13] \"stats\"     \"graphics\"  \"grDevices\" \"utils\"     \"datasets\"  \"methods\"  \n[19] \"base\"     \n\n[[5]]\n [1] \"lme4\"      \"Matrix\"    \"lubridate\" \"forcats\"   \"stringr\"   \"dplyr\"    \n [7] \"purrr\"     \"readr\"     \"tidyr\"     \"tibble\"    \"ggplot2\"   \"tidyverse\"\n[13] \"stats\"     \"graphics\"  \"grDevices\" \"utils\"     \"datasets\"  \"methods\"  \n[19] \"base\"     \n\n[[6]]\n [1] \"naniar\"    \"lme4\"      \"Matrix\"    \"lubridate\" \"forcats\"   \"stringr\"  \n [7] \"dplyr\"     \"purrr\"     \"readr\"     \"tidyr\"     \"tibble\"    \"ggplot2\"  \n[13] \"tidyverse\" \"stats\"     \"graphics\"  \"grDevices\" \"utils\"     \"datasets\" \n[19] \"methods\"   \"base\"     \n\n[[7]]\n [1] \"nortest\"   \"naniar\"    \"lme4\"      \"Matrix\"    \"lubridate\" \"forcats\"  \n [7] \"stringr\"   \"dplyr\"     \"purrr\"     \"readr\"     \"tidyr\"     \"tibble\"   \n[13] \"ggplot2\"   \"tidyverse\" \"stats\"     \"graphics\"  \"grDevices\" \"utils\"    \n[19] \"datasets\"  \"methods\"   \"base\"     \n\n\nGreat! Now let’s load our data from GitHub.\n\nurl &lt;- \"https://raw.githubusercontent.com/madpax-csv/madpax-does-stats/refs/heads/master/wNAs_FourWaves_FTlevel.csv\"\nFFH &lt;- read_csv(url)\n\nWarning: One or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\n\n\nRows: 8064 Columns: 169\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr   (6): gender_FR, race_FR, distance_mi_cats, race_cat, H_FriendID_, Time\ndbl (157): ID, over18, inFSI, age, gender, transgender, international, frien...\nnum   (3): race, selectHomeFriend, listPton\nlgl   (3): loneliness, winterPlan, composite_Lon_Men\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n#You may get an error about parsing issues, but it looks normal to me... \n\nExplain dataset.\nThe Adversity and Close Relationships Lab surveyed students about their friendships at four different time points throughout their first year of college.\nIn the summer (Intake) before they moved on campus, we asked them to list up to 7 current friends and how close they are to each friend, how long they’ve been friends, and whether this friend is in college.\nThen, in the Fall, Winter, and Spring, we asked if they still consider this person a friend. If they do, we then ask about how close they are to that friend now. (We do not ask about length of friendship or college enrollment for these friends again.)\nWe are using a few key variables:\n\nID: This is a given surveyed participants’ unique ID number.\nTime: This refers to the time point at which responses were given (i.e., Intake, Fall, Winter, Spring).\nH_FriendID_: This is a unique ID for each friend that a participant listed.\nH_closeFriend: This refers to how close a participant rated a friend at a given timepoint.\n\n1 = Not At All Close; 5 = Extremely Close\n\n\nWe may also look at a few controls and moderators, which I will include in our dataset for now, and will explain later when we come to it.\nBefore we dive in, let’s widdle down our dataset FFH (friends from home) to make it easier to explore. We’ll also quickly ensure the data types are appropriate.\n\nFFH &lt;- FFH %&gt;%\n  select(\n    #Main variables of interest\n    ID, Time, H_FriendID_, H_closeFriend,\n    #Potential Moderators\n    H_Friend_college,\n    #For Filtering\n    H_friend_in_Net) %&gt;%\n  mutate(\n    ID = as.character(ID),\n    Time = factor(Time, levels = c(\"Intake\", \"Fall\", \"Winter\", \"Spring\")),\n    H_FriendID_ = as.character(H_FriendID_),\n    H_closeFriend = as.numeric(H_closeFriend),\n    H_Friend_college = factor(H_Friend_college, levels = c(0, 1))  )\nFFH &lt;- FFH %&gt;%\n  select(ID, H_FriendID_, everything())\n\nWalk through dataset and its structure.\nOur data is at the Friend/Time level. This means that each row represents how our participant thought of a friend at a given timepoint.\nBelow, you can print an example of how one participant responded about one friend at each timepoint. Notice how the ID and the Friend ID are both the same in each row, but the time point differs.\n\nstructure_ex &lt;- FFH %&gt;%\n  filter(ID == \"211810\" & H_FriendID_ == \"1\")\n  \nprint(structure_ex)\n\n# A tibble: 4 × 6\n  ID     H_FriendID_ Time   H_closeFriend H_Friend_college H_friend_in_Net\n  &lt;chr&gt;  &lt;chr&gt;       &lt;fct&gt;          &lt;dbl&gt; &lt;fct&gt;                      &lt;dbl&gt;\n1 211810 1           Intake             5 1                              1\n2 211810 1           Fall               5 1                              1\n3 211810 1           Winter             3 1                              1\n4 211810 1           Spring             4 1                              1\n\n\nLet’s look at all of the friends this participant listed to better understand the structure of the data.\nYou’ll notice that each Participant (ID) has at least one friend (H_FriendID_) and for each friend, there is a time point (Time). In other words…\nParticipant (ID) → Friend (H_FriendID_) → Time point (Time)\nLevel 1: Repeated measurements (e.g., closeness over time)\nLevel 2: Friend-level variables (e.g., how long they’ve known each friend)\nLevel 3: Participant-level variables (e.g., age, inFSI)\n\nstructure_ex2 &lt;- FFH %&gt;%\n  filter(ID == \"211810\")\n  \nprint(structure_ex2)\n\n# A tibble: 28 × 6\n   ID     H_FriendID_ Time   H_closeFriend H_Friend_college H_friend_in_Net\n   &lt;chr&gt;  &lt;chr&gt;       &lt;fct&gt;          &lt;dbl&gt; &lt;fct&gt;                      &lt;dbl&gt;\n 1 211810 1           Intake             5 1                              1\n 2 211810 1           Fall               5 1                              1\n 3 211810 1           Winter             3 1                              1\n 4 211810 1           Spring             4 1                              1\n 5 211810 320         Intake             5 1                              1\n 6 211810 320         Fall               5 1                              1\n 7 211810 320         Winter             5 1                              1\n 8 211810 320         Spring             4 1                              1\n 9 211810 634         Intake             4 1                              1\n10 211810 634         Fall               3 1                              1\n# ℹ 18 more rows\n\n\nLet’s take a glimpse at our data.\n\nglimpse(FFH)\n\nRows: 8,064\nColumns: 6\n$ ID               &lt;chr&gt; \"211810\", \"211810\", \"211810\", \"211810\", \"211810\", \"21…\n$ H_FriendID_      &lt;chr&gt; \"1\", \"1\", \"1\", \"1\", \"320\", \"320\", \"320\", \"320\", \"634\"…\n$ Time             &lt;fct&gt; Intake, Fall, Winter, Spring, Intake, Fall, Winter, S…\n$ H_closeFriend    &lt;dbl&gt; 5, 5, 3, 4, 5, 5, 5, 4, 4, 3, NA, NA, 3, 3, NA, NA, N…\n$ H_Friend_college &lt;fct&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, NA, N…\n$ H_friend_in_Net  &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, NA, N…\n\ngg_miss_var(FFH)\n\n\n\n\n\n\n\n\nYou might notice that while we have very few missing values for participant-level variables like age, there are many more missing values for friend-related variables. These missing values arise for two main reasons:\n\nNot all participants listed 7 friends during the Intake survey—some listed fewer, leaving empty friend slots for information about closeness etc.\nNot all friends were still considered friends at each time point (Fall, Winter, Spring), so their closeness ratings are missing for those waves\n\nLet’s address each of these points. Luckily, in another file, our data has already noted when a participant hasn’t listed someone in a given slot. So we are going to remove those slots where no one was listed. Let’s see the effect that this had.\nWe can see that those questions that were ONLY asked in Intake are now only missing for 5 participants – and we can assume that 5 people skipped one of those questions.\n\nFFH &lt;- FFH %&gt;%\n  filter(H_FriendID_ != \"none listed\")\ngg_miss_var(FFH)\n\n\n\n\n\n\n\nwhy &lt;- FFH %&gt;%\n  filter(is.na(H_Friend_college))\nn_distinct(why$ID)\n\n[1] 5\n\n\nWhen a person listed as a friend at Intake is no longer named in Fall, Winter, or Spring, their closeness rating is left missing by default. However, this missingness is meaningful—it reflects the potential loss of a friendship, which is theoretically important. Rather than removing these cases, we recode their missing closeness values to 1, representing “Not at all close” on our scale. This allows us to retain these friends in the dataset and interpret their absence as a signal of relationship deterioration.\n\nFFH &lt;- FFH %&gt;%\n  mutate(H_closeFriend = if_else(H_friend_in_Net == 0, 1, H_closeFriend))\n\nAt this stage, any remaining missing values reflect questions that participants skipped. For simplicity, we’ll remove those cases. (Not really the main point of this tutorial)\n\nFFH &lt;- FFH %&gt;%\n  drop_na()\n\nLet’s take a quick look at more information about our data.\n\nn_participants &lt;- n_distinct(FFH$ID)\nprint(paste(\"Number of unique participants:\", n_participants))\n\n[1] \"Number of unique participants: 283\"\n\nn_friends &lt;- n_distinct(FFH$H_FriendID_)\nprint(paste(\"Number of unique friends listed:\", n_friends))\n\n[1] \"Number of unique friends listed: 1594\"\n\nFFH %&gt;%\n  ggplot(aes(x = H_closeFriend)) +\n  geom_histogram(binwidth = 1, fill = \"steelblue\", color = \"white\", boundary = 0) +\n  facet_wrap(~Time) +\n  labs(title = \"Histogram of Closeness by Timepoint\",\n       x = \"Closeness (1 = Not at all close, 5 = Extremely close)\",\n       y = \"Count\") +\n  theme_minimal() +\n  theme(panel.grid = element_blank())\n\n\n\n\n\n\n\nlillie.test(FFH$H_closeFriend)\n\n\n    Lilliefors (Kolmogorov-Smirnov) normality test\n\ndata:  FFH$H_closeFriend\nD = 0.19051, p-value &lt; 2.2e-16\n\n\nSo, we have 288 participants and 1,617 unique friends listed. In the table, you’ll see a breakdown of closeness at each time point. These histograms, plus a quick test of normality, show that our outcome is not normally distributed. But, it’s worth making our model and then investigating once the model is set.\nNow that we know what we’re working with, we can start to decipher a model to investigate our research question:\nWhat is the effect of Time on Closeness to friends from home?\nBecause of the nested nature of this data, our biggest contender is a mixed linear regression.\nA mixed linear model (also called a multilevel or hierarchical linear model) is a type of regression that accounts for nested or grouped data.\nIn our case, closeness ratings are repeated over time within each friend, and each friend is nested within a participant. This violates the assumption of independence in traditional linear regression, because observations from the same person or the same friendship are likely to be more similar to each other than to those from others. A mixed linear regression is ideal here because it allows us to model both fixed effects (like time) and random effects (like variation across participants and friendships). This helps us better understand the average trends while also accounting for individual differences in how close someone feels to their friends in general.\nBut first, we need to check a few assumptions to make sure this is the right model for us."
  },
  {
    "objectID": "posts/Tutorial/tut_index.html#fit-model",
    "href": "posts/Tutorial/tut_index.html#fit-model",
    "title": "Tutorial",
    "section": "Fit Model",
    "text": "Fit Model\nNow let’s fit our model. Below, we model…\nThe effect of Time on closeness H_closeFriend with random effects.\n\nlibrary(lmerTest)\n\n\nAttaching package: 'lmerTest'\n\n\nThe following object is masked from 'package:lme4':\n\n    lmer\n\n\nThe following object is masked from 'package:stats':\n\n    step\n\nmain_analysis &lt;- lmer(\nH_closeFriend ~ Time +\n  (1 + Time | ID) +        # each participant has their own baseline closeness AND their own Time‐trend  \n  (1 | ID:H_FriendID_),    # each friendship (within participant) has its own baseline closeness\n  data = FFH)\nsummary(main_analysis)\n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: H_closeFriend ~ Time + (1 + Time | ID) + (1 | ID:H_FriendID_)\n   Data: FFH\n\nREML criterion at convergence: 17480\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-4.0237 -0.4102 -0.0027  0.4434  3.9172 \n\nRandom effects:\n Groups         Name        Variance Std.Dev. Corr             \n ID:H_FriendID_ (Intercept) 0.4267   0.6532                    \n ID             (Intercept) 0.2074   0.4554                    \n                TimeFall    1.7141   1.3093   -0.22            \n                TimeWinter  1.5641   1.2507   -0.39  0.61      \n                TimeSpring  1.5153   1.2310   -0.30  0.47  0.65\n Residual                   0.4244   0.6514                    \nNumber of obs: 6370, groups:  ID:H_FriendID_, 1594; ID, 283\n\nFixed effects:\n             Estimate Std. Error        df t value            Pr(&gt;|t|)    \n(Intercept)   4.00413    0.03608 275.77176  110.99 &lt;0.0000000000000002 ***\nTimeFall     -1.02991    0.08161 279.20311  -12.62 &lt;0.0000000000000002 ***\nTimeWinter   -1.30645    0.07836 277.60357  -16.67 &lt;0.0000000000000002 ***\nTimeSpring   -1.56769    0.07717 279.89139  -20.31 &lt;0.0000000000000002 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n           (Intr) TimFll TmWntr\nTimeFall   -0.253              \nTimeWinter -0.378  0.596       \nTimeSpring -0.316  0.472  0.632\n\n\nWe can see from this model that each time point is associated with a significant drop in closeness, even with our random effects."
  },
  {
    "objectID": "posts/Tutorial/tut_index.html#visualize-model",
    "href": "posts/Tutorial/tut_index.html#visualize-model",
    "title": "Tutorial",
    "section": "Visualize Model",
    "text": "Visualize Model\nLet’s visualize the model to further our understanding.\n\nlibrary(emmeans)\n\nWelcome to emmeans.\nCaution: You lose important information if you filter this package's results.\nSee '? untidy'\n\n# 1a. Get estimated marginal means\nemm &lt;- emmeans(main_analysis, ~ Time, pbkrtest.limit = 6462)\n\n# 1b. Turn into a data frame\nemm_df &lt;- as.data.frame(emm)\n\n# 1c. Plot\nmain_plot&lt;- ggplot(emm_df, aes(x = Time, y = emmean)) +\n  geom_line(group = 1) +\n  geom_point(size = 3) +\n  geom_errorbar(aes(ymin = lower.CL, ymax = upper.CL), width = .1) +\n  labs(\n    title = \"Estimated Mean Closeness by Wave\",\n    y = \"Predicted Closeness (±95% CI)\"\n  ) +\n  ylim(1,5)+\n  theme_classic()\n\nprint(main_plot)\n\n\n\n\n\n\n\n\nLet’s take a closer look at the random effects we’ve been modeling.\nFor that participant, we can now see how closeness to each friend rises or falls over the four waves—making the friend‐level variation explicit.\n\n# 1. Filter for one participant\npid &lt;- \"211810\"\ndf_pid &lt;- FFH %&gt;% filter(ID == pid)\n\n# 2. Add model‐predicted closeness (including both random intercepts/slopes)\ndf_pid &lt;- df_pid %&gt;%\n  mutate(pred = predict(main_analysis,\n                        newdata = .,\n                        re.form = ~(1 + Time | ID) + (1 | ID:H_FriendID_)))\n\n# 3. Plot each friend’s trajectory\nggplot(df_pid, aes(x = Time, y = pred, group = H_FriendID_, color = H_FriendID_)) +\n  geom_line() +\n  geom_point() +\n  labs(title = paste0(\"Participant \", pid, \": \\nFriend‐level Closeness Trajectories\"),\n       y = \"Predicted Closeness\") +\n  theme_classic() +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\nWe can even take a look at 20 cases from our model to see how individual trajectories differ from the average trend. By randomly sampling 20 participants and plotting their fitted closeness over time (using their own intercepts and slopes), this “spaghetti” plot makes the heterogeneity in change visible—some people’s closeness remains high and stable, others decline sharply, and many show more gradual shifts. This visualization adds value by showing exactly what the random‐slope term captures: it turns a single fixed‐effect line into a cloud of subject‐specific lines, helping us judge whether the average Time effect truly represents our sample or masks important individual differences.\n\n# 2a. pick 20 random IDs\nset.seed(42)\nids20 &lt;- sample(unique(FFH$ID), 20)\n\n# 2b. augment data with fitted values\ndf20 &lt;- FFH %&gt;%\n  filter(ID %in% ids20) %&gt;%\n  mutate(\n    pred = predict(main_analysis,\n                   newdata = .,    # same data\n                   re.form = ~(1 + Time | ID))  # include participant randoms\n  )\n\n# 2c. plot\nggplot(df20, aes(x = Time, y = pred, group = ID, color = ID)) +\n  geom_line() +\n  geom_point() +\n  labs(\n    title = \"Subject‐specific Closeness Trajectories\",\n    y = \"Fitted Closeness\"\n  ) +\n  theme_classic() +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\nAmazing!"
  },
  {
    "objectID": "posts/Tutorial/tut_index.html#testing-model-validity-further",
    "href": "posts/Tutorial/tut_index.html#testing-model-validity-further",
    "title": "Tutorial",
    "section": "Testing Model Validity Further",
    "text": "Testing Model Validity Further\nLet’s run a few more tests to be sure that our model is valid.\nRemember we had some abnormality as far as the normality of the distribution of our outcome variable. Let’s see how this effects our model.\nWhat we see below is that in our normality test, the p-value &lt; 2.2×10⁻²² is astronomically small, so we have to reject the null hypothesis of “residuals are normally distributed.”\nBut with such a large sample (n ≈ 6,462), even tiny departures can give very low p-values. It’s best to:\n\nInspect a Q-Q plot of the residuals to judge practical importance, and…\nRemember that mixed models are fairly robust to modest normality violations—especially with balanced designs and large samples.\n\nIn the QQ Plot below, we see that actually, our data follows the line of “normality” alright afterall, with a bit of heavier tails than a perfect normal—i.e. a few residuals are more extreme than you’d expect under strict normality.\nWith ~6,500 observations, these mild deviations are common and usually not fatal for inference in a mixed model.\n\nlibrary(nortest)\nlillie.test(residuals(main_analysis))\n\n\n    Lilliefors (Kolmogorov-Smirnov) normality test\n\ndata:  residuals(main_analysis)\nD = 0.061099, p-value &lt; 0.00000000000000022\n\n# extract residuals\nres &lt;- residuals(main_analysis)\n\n# Q–Q plot\nqqnorm(residuals(main_analysis))\nqqline(residuals(main_analysis), col = \"blue\", lwd = 2)\n\n\n\n\n\n\n\n\nIf that’s the case – that we just have a few outliers influencing our model, let’s take a look at the most influential obesrvations and see if our model changes as a result.\nWe see many\n\n# install.packages(\"performance\")\nlibrary(performance)\nlibrary(see)\nout &lt;- check_outliers(main_analysis, \"zscore_robust\")\n\nConverting missing values (`NA`) into regular values currently not\n  possible for variables of class `NULL`.\n\nprint(out)\n\nOK: No outliers detected.\n- Based on the following method and threshold: zscore_robust (3.291).\n- For variable: (Whole model)\n\ncheck_autocorrelation(main_analysis)\n\nWarning: Autocorrelated residuals detected (p &lt; .001).\n\ncheck_singularity(main_analysis)\n\n[1] FALSE\n\ncheck_model(main_analysis)\n\n\n\n\n\n\n\n\n\n#\n# linear mixed‐model\n# library(lme4)\n# mod_lm &lt;- lmer(as.numeric(H_closeFriend) ~ Time + (1|ID) + (1|ID:H_FriendID_), data=FFH)\n# AIC(mod_lm); BIC(mod_lm)\n# \n# # ordinal mixed‐model -- can't do slopes so we removed sloeps from both models.??? \n# library(ordinal)\n# mod_ord &lt;- clmm(as.factor(H_closeFriend)       \n#             ~ Time + (1|ID) + (1|ID:H_FriendID_), data=FFH, link=\"logit\")\n# AIC(mod_ord, mod_lm, main_analysis); BIC(mod_ord, mod_lm, main_analysis)\n# \n# theme_set(theme_classic(base_size = 6))\n# nominal_test(mod_ord)\n\nAdd in a moderator.\nVisualize.\nCompare.\nConclusions and Wrap Up.\n\nprint(\"hi\")\n\n[1] \"hi\""
  },
  {
    "objectID": "5.5.25AppPilot.html",
    "href": "5.5.25AppPilot.html",
    "title": "madpax does stats",
    "section": "",
    "text": "title: “App Pilot” author: “MKP” date: “2025-05-06” output: html_document ———————-"
  },
  {
    "objectID": "5.5.25AppPilot.html#load-raw-data",
    "href": "5.5.25AppPilot.html#load-raw-data",
    "title": "madpax does stats",
    "section": "Load raw data",
    "text": "Load raw data\n\nfile_path &lt;- \"~/Downloads/Connection App Pilot_May 5, 2025_19.40.csv\"\npilot_raw &lt;- readr::read_csv(file_path)"
  },
  {
    "objectID": "5.5.25AppPilot.html#extract-question-lookup",
    "href": "5.5.25AppPilot.html#extract-question-lookup",
    "title": "madpax does stats",
    "section": "Extract question lookup",
    "text": "Extract question lookup\n\nquestions &lt;- pilot_raw %&gt;%\n  slice(1) %&gt;%\n  tidyr::pivot_longer(\n    cols      = everything(),\n    names_to  = \"name\",\n    values_to = \"text\"\n  )"
  },
  {
    "objectID": "5.5.25AppPilot.html#clean-and-recode-data",
    "href": "5.5.25AppPilot.html#clean-and-recode-data",
    "title": "madpax does stats",
    "section": "Clean and recode data",
    "text": "Clean and recode data\n\npilot &lt;- pilot_raw %&gt;%\n  # drop preview rows and header rows\n  filter(DistributionChannel != \"preview\") %&gt;%\n  slice(-1, -2) %&gt;%\n  # select ID plus all Q_* and ranking cols\n  select(ResponseId, contains(\"Q\"), starts_with(\"ReasonsFriends_\")) %&gt;%\n  # rename top-three age/location questions\n  rename(\n    Q_Age       = `Q_Dmg_Age.Home.Now._1`,\n    Q_Hometown  = `Q_Dmg_Age.Home.Now._2`,\n    Q_LivingNow = `Q_Dmg_Age.Home.Now._3`\n  ) %&gt;%\n  # numeric conversion\n  mutate(\n    across(1:13, as.numeric),\n    across(\n      c(Q_Age, Q_Gender, Q_Race, Q_Military,\n        Q_Edu, Q_Romantic, Q_Parent),\n      as.numeric\n    ),\n    # factor recodes\n    Q_Edu = factor(\n      Q_Edu,\n      levels = 1:7,\n      labels = c(\n        \"Some high school or less\",\n        \"High school diploma or GED\",\n        \"Some college, but no degree\",\n        \"Associates or technical degree\",\n        \"Bachelor’s degree\",\n        \"Graduate or professional degree\",\n        \"Prefer not to say\"\n      )\n    ),\n    Q_Race = factor(\n      Q_Race,\n      levels = 1:7,\n      labels = c(\n        \"White or Caucasian\",\n        \"Black or African American\",\n        \"American Indian/Native American or Alaska Native\",\n        \"Asian\",\n        \"Native Hawaiian or Other Pacific Islander\",\n        \"Other\",\n        \"Prefer not to say\"\n      )\n    ),\n    Q_Gender = factor(\n      Q_Gender,\n      levels = 1:5,\n      labels = c(\n        \"Man\",\n        \"Woman\",\n        \"Non-binary / third gender\",\n        \"Prefer to self-describe\",\n        \"Prefer not to say\"\n      )\n    )\n  )"
  },
  {
    "objectID": "5.5.25AppPilot.html#quick-histograms",
    "href": "5.5.25AppPilot.html#quick-histograms",
    "title": "madpax does stats",
    "section": "Quick histograms",
    "text": "Quick histograms\n\n# All numeric Q_* variables\nDataExplorer::plot_histogram(pilot)\n\n\n\n\n\n\n\n\n\n# Demographics only\ndemo_vars &lt;- c(\n  \"Q_Age\", \"Q_Gender\", \"Q_Race\",\n  \"Q_Military\", \"Q_Romantic\", \"Q_Edu\", \"Q_Parent\"\n)\nDataExplorer::plot_histogram(pilot[demo_vars])\n\n\n\n\n\n\n\nDataExplorer::plot_bar(pilot[demo_vars])"
  },
  {
    "objectID": "5.5.25AppPilot.html#average-ranking-for-group0-items",
    "href": "5.5.25AppPilot.html#average-ranking-for-group0-items",
    "title": "madpax does stats",
    "section": "Average ranking for group0 items",
    "text": "Average ranking for group0 items\n\nitem_labels &lt;- c(\n  \"1\"  = \"I simply forget to stay in contact.\",\n  \"2\"  = \"I have trouble making time to reach out.\",\n  \"3\"  = \"The conversation might not be enjoyable.\",\n  \"4\"  = \"Socializing takes a lot of energy for me.\",\n  \"5\"  = \"I don't know what we'll talk about.\",\n  \"6\"  = \"I'd rather spend time in-person.\",\n  \"7\"  = \"I don't want to bother that person.\",\n  \"8\"  = \"I don't like texting/calling.\",\n  \"9\"  = \"I feel like the other person should reach out.\",\n  \"10\" = \"The conversation might be awkward.\"\n)\n\navg_rank_group0 &lt;- pilot %&gt;%\n  select(ResponseId, starts_with(\"ReasonsFriends_0\")) %&gt;%\n  pivot_longer(\n    cols      = -ResponseId,\n    names_to  = \"col\",\n    values_to = \"rank\"\n  ) %&gt;%\n  mutate(\n    item = sub(\"ReasonsFriends_0_(\\\\d+)_RANK\", \"\\\\1\", col),\n    rank = as.integer(rank)\n  ) %&gt;%\n  group_by(item) %&gt;%\n  summarise(\n    avg_rank    = mean(rank,    na.rm = TRUE),\n    pct_top1    = mean(rank == 1, na.rm = TRUE) * 100,\n    pct_problem = mean(!is.na(rank)) * 100,\n    .groups     = \"drop\"\n  ) %&gt;%\n  mutate(\n    item = item_labels[item]\n  ) %&gt;%\n  arrange(avg_rank)\n\navg_rank_group0\n\n# A tibble: 11 × 4\n   item                                           avg_rank pct_top1 pct_problem\n   &lt;chr&gt;                                             &lt;dbl&gt;    &lt;dbl&gt;       &lt;dbl&gt;\n 1 I have trouble making time to reach out.           2.69    20.7         79.5\n 2 I simply forget to stay in contact.                2.83    24.1         79.5\n 3 I don't want to bother that person.                2.94    30.3         45.2\n 4 I'd rather spend time in-person.                   3.14    26           68.5\n 5 Socializing takes a lot of energy for me.          3.42    12.9         42.5\n 6 The conversation might not be enjoyable.           4       12.5         11.0\n 7 The conversation might be awkward.                 4.12    32           34.2\n 8 I don't know what we'll talk about.                4.21     0           26.0\n 9 I don't like texting/calling.                      4.26    11.1         37.0\n10 I feel like the other person should reach out.     4.38     4.17        32.9\n11 &lt;NA&gt;                                             NaN      NaN            0"
  }
]