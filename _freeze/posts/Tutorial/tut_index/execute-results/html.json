{
  "hash": "9132ffadb55a0ac92f96073bb18e9cdd",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Tutorial\"\noutput-dir: docs\nauthor: \"Maddy Paxson\"\ndate: \"2025-05-02\"\ncategories: [research]\n---\n\n\n\n# Introduction to the Project\n\nHi, welcome to my first tutorial!\n\nToday, we're going to be trying to understand how friendships change during the transition to college.\n\nBut first, let's load and install all of the packages we'll need. Run the code below to install packages you may not already have.\n\n## Install and Load Packages\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#List of packages we'll use. \n\npackages <- c(\"tidyverse\",\"dplyr\", \"lme4\", \"ggplot2\", \"readr\",\"naniar\",\"nortest\")  \n#Identifies which packages you already have\ninstall_if_missing <- setdiff(packages, rownames(installed.packages()))\n#Installs packages you don't have\nif (length(install_if_missing)) install.packages(install_if_missing)\n#Calls all needed packages \nlapply(packages, library, character.only = TRUE)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\nLoading required package: Matrix\n\n\nAttaching package: 'Matrix'\n\n\nThe following objects are masked from 'package:tidyr':\n\n    expand, pack, unpack\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[[1]]\n [1] \"lubridate\" \"forcats\"   \"stringr\"   \"dplyr\"     \"purrr\"     \"readr\"    \n [7] \"tidyr\"     \"tibble\"    \"ggplot2\"   \"tidyverse\" \"stats\"     \"graphics\" \n[13] \"grDevices\" \"utils\"     \"datasets\"  \"methods\"   \"base\"     \n\n[[2]]\n [1] \"lubridate\" \"forcats\"   \"stringr\"   \"dplyr\"     \"purrr\"     \"readr\"    \n [7] \"tidyr\"     \"tibble\"    \"ggplot2\"   \"tidyverse\" \"stats\"     \"graphics\" \n[13] \"grDevices\" \"utils\"     \"datasets\"  \"methods\"   \"base\"     \n\n[[3]]\n [1] \"lme4\"      \"Matrix\"    \"lubridate\" \"forcats\"   \"stringr\"   \"dplyr\"    \n [7] \"purrr\"     \"readr\"     \"tidyr\"     \"tibble\"    \"ggplot2\"   \"tidyverse\"\n[13] \"stats\"     \"graphics\"  \"grDevices\" \"utils\"     \"datasets\"  \"methods\"  \n[19] \"base\"     \n\n[[4]]\n [1] \"lme4\"      \"Matrix\"    \"lubridate\" \"forcats\"   \"stringr\"   \"dplyr\"    \n [7] \"purrr\"     \"readr\"     \"tidyr\"     \"tibble\"    \"ggplot2\"   \"tidyverse\"\n[13] \"stats\"     \"graphics\"  \"grDevices\" \"utils\"     \"datasets\"  \"methods\"  \n[19] \"base\"     \n\n[[5]]\n [1] \"lme4\"      \"Matrix\"    \"lubridate\" \"forcats\"   \"stringr\"   \"dplyr\"    \n [7] \"purrr\"     \"readr\"     \"tidyr\"     \"tibble\"    \"ggplot2\"   \"tidyverse\"\n[13] \"stats\"     \"graphics\"  \"grDevices\" \"utils\"     \"datasets\"  \"methods\"  \n[19] \"base\"     \n\n[[6]]\n [1] \"naniar\"    \"lme4\"      \"Matrix\"    \"lubridate\" \"forcats\"   \"stringr\"  \n [7] \"dplyr\"     \"purrr\"     \"readr\"     \"tidyr\"     \"tibble\"    \"ggplot2\"  \n[13] \"tidyverse\" \"stats\"     \"graphics\"  \"grDevices\" \"utils\"     \"datasets\" \n[19] \"methods\"   \"base\"     \n\n[[7]]\n [1] \"nortest\"   \"naniar\"    \"lme4\"      \"Matrix\"    \"lubridate\" \"forcats\"  \n [7] \"stringr\"   \"dplyr\"     \"purrr\"     \"readr\"     \"tidyr\"     \"tibble\"   \n[13] \"ggplot2\"   \"tidyverse\" \"stats\"     \"graphics\"  \"grDevices\" \"utils\"    \n[19] \"datasets\"  \"methods\"   \"base\"     \n```\n\n\n:::\n:::\n\n\n\nGreat! Now let's load our data from GitHub.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nurl <- \"https://raw.githubusercontent.com/madpax-csv/madpax-does-stats/refs/heads/master/wNAs_FourWaves_FTlevel.csv\"\nFFH <- read_csv(url)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: One or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat <- vroom(...)\n  problems(dat)\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nRows: 8064 Columns: 169\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr   (6): gender_FR, race_FR, distance_mi_cats, race_cat, H_FriendID_, Time\ndbl (157): ID, over18, inFSI, age, gender, transgender, international, frien...\nnum   (3): race, selectHomeFriend, listPton\nlgl   (3): loneliness, winterPlan, composite_Lon_Men\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n\n\n:::\n\n```{.r .cell-code}\n#You may get an error about parsing issues, but it looks normal to me... \n```\n:::\n\n\n\n**Explain dataset.**\n\nThe Adversity and Close Relationships Lab surveyed students about their friendships at four different time points throughout their first year of college.\n\nIn the summer (**Intake**) before they moved on campus, we asked them to list up to 7 current friends and how close they are to each friend, how long they've been friends, and whether this friend is in college.\n\nThen, in the Fall, Winter, and Spring, we asked if they still consider this person a friend. If they do, we then ask about how close they are to that friend now. (We do not ask about length of friendship or college enrollment for these friends again.)\n\nWe are using a few key variables:\n\n-   **`ID`:** This is a given surveyed participants' unique ID number.\n\n-   **`Time`:** This refers to the time point at which responses were given (i.e., Intake, Fall, Winter, Spring).\n\n-   **`H_FriendID_`:** This is a unique ID for each friend that a participant listed.\n\n-   **`H_closeFriend`:** This refers to how close a participant rated a friend at a given timepoint.\n\n    -   1 = Not At All Close; 5 = Extremely Close\n\nWe may also look at a few controls and moderators, which I will include in our dataset for now, and will explain later when we come to it.\n\nBefore we dive in, let's widdle down our dataset **FFH (friends from home)** to make it easier to explore. We'll also quickly ensure the data types are appropriate.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nFFH <- FFH %>%\n  select(\n    #Main variables of interest\n    ID, Time, H_FriendID_, H_closeFriend,\n    #Potential Moderators\n    H_Friend_college,\n    #For Filtering\n    H_friend_in_Net) %>%\n  mutate(\n    ID = as.character(ID),\n    Time = factor(Time, levels = c(\"Intake\", \"Fall\", \"Winter\", \"Spring\")),\n    H_FriendID_ = as.character(H_FriendID_),\n    H_closeFriend = as.numeric(H_closeFriend),\n    H_Friend_college = factor(H_Friend_college, levels = c(0, 1))  )\nFFH <- FFH %>%\n  select(ID, H_FriendID_, everything())\n```\n:::\n\n\n\n**Walk through dataset and its structure.**\n\n**Our data is at the Friend/Time level. This means that each row represents how our participant thought of a friend at a given timepoint.**\n\nBelow, you can print an example of how one participant responded about one friend at each timepoint. Notice how the ID and the Friend ID are both the same in each row, but the time point differs.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstructure_ex <- FFH %>%\n  filter(ID == \"211810\" & H_FriendID_ == \"1\")\n  \nprint(structure_ex)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 4 × 6\n  ID     H_FriendID_ Time   H_closeFriend H_Friend_college H_friend_in_Net\n  <chr>  <chr>       <fct>          <dbl> <fct>                      <dbl>\n1 211810 1           Intake             5 1                              1\n2 211810 1           Fall               5 1                              1\n3 211810 1           Winter             3 1                              1\n4 211810 1           Spring             4 1                              1\n```\n\n\n:::\n:::\n\n\n\nLet's look at all of the friends this participant listed to better understand the structure of the data.\n\nYou'll notice that each Participant (**ID**) has at least one friend (**H_FriendID\\_**) and for each friend, there is a time point (**Time**). In other words...\n\n**Participant (`ID`) → Friend (`H_FriendID_`) → Time point (`Time`)**\n\nLevel 1: Repeated measurements (e.g., closeness over time)\n\nLevel 2: Friend-level variables (e.g., how long they’ve known each friend)\n\nLevel 3: Participant-level variables (e.g., age, inFSI)\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstructure_ex2 <- FFH %>%\n  filter(ID == \"211810\")\n  \nprint(structure_ex2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 28 × 6\n   ID     H_FriendID_ Time   H_closeFriend H_Friend_college H_friend_in_Net\n   <chr>  <chr>       <fct>          <dbl> <fct>                      <dbl>\n 1 211810 1           Intake             5 1                              1\n 2 211810 1           Fall               5 1                              1\n 3 211810 1           Winter             3 1                              1\n 4 211810 1           Spring             4 1                              1\n 5 211810 320         Intake             5 1                              1\n 6 211810 320         Fall               5 1                              1\n 7 211810 320         Winter             5 1                              1\n 8 211810 320         Spring             4 1                              1\n 9 211810 634         Intake             4 1                              1\n10 211810 634         Fall               3 1                              1\n# ℹ 18 more rows\n```\n\n\n:::\n:::\n\n\n\nLet's take a glimpse at our data.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglimpse(FFH)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 8,064\nColumns: 6\n$ ID               <chr> \"211810\", \"211810\", \"211810\", \"211810\", \"211810\", \"21…\n$ H_FriendID_      <chr> \"1\", \"1\", \"1\", \"1\", \"320\", \"320\", \"320\", \"320\", \"634\"…\n$ Time             <fct> Intake, Fall, Winter, Spring, Intake, Fall, Winter, S…\n$ H_closeFriend    <dbl> 5, 5, 3, 4, 5, 5, 5, 4, 4, 3, NA, NA, 3, 3, NA, NA, N…\n$ H_Friend_college <fct> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, NA, N…\n$ H_friend_in_Net  <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, NA, N…\n```\n\n\n:::\n\n```{.r .cell-code}\ngg_miss_var(FFH)\n```\n\n::: {.cell-output-display}\n![](tut_index_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n\n\nYou might notice that while we have very few missing values for participant-level variables like age, there are many more missing values for friend-related variables. These missing values arise for two main reasons:\n\n1.  **Not all participants listed 7 friends** during the Intake survey—some listed fewer, leaving empty friend slots for information about closeness etc.\n\n2.  **Not all friends were still considered friends** at each time point (Fall, Winter, Spring), so their closeness ratings are missing for those waves\n\nLet's address each of these points. Luckily, in another file, our data has already noted when a participant hasn't listed someone in a given slot. So we are going to remove those slots where no one was listed. Let's see the effect that this had.\n\nWe can see that those questions that were ONLY asked in Intake are now only missing for 5 participants – and we can assume that 5 people skipped one of those questions.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nFFH <- FFH %>%\n  filter(H_FriendID_ != \"none listed\")\ngg_miss_var(FFH)\n```\n\n::: {.cell-output-display}\n![](tut_index_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n\n```{.r .cell-code}\nwhy <- FFH %>%\n  filter(is.na(H_Friend_college))\nn_distinct(why$ID)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 5\n```\n\n\n:::\n:::\n\n\n\nWhen a person listed as a friend at Intake is no longer named in Fall, Winter, or Spring, their closeness rating is left missing by default. However, this missingness is meaningful—it reflects the potential loss of a friendship, which is theoretically important. Rather than removing these cases, we recode their missing closeness values to 1, representing \"Not at all close\" on our scale. This allows us to retain these friends in the dataset and interpret their absence as a signal of relationship deterioration.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nFFH <- FFH %>%\n  mutate(H_closeFriend = if_else(H_friend_in_Net == 0, 1, H_closeFriend))\n```\n:::\n\n\n\nAt this stage, any remaining missing values reflect questions that participants skipped. For simplicity, we’ll remove those cases. (Not really the main point of this tutorial)\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nFFH <- FFH %>%\n  drop_na()\n```\n:::\n\n\n\nLet's take a quick look at more information about our data.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nn_participants <- n_distinct(FFH$ID)\nprint(paste(\"Number of unique participants:\", n_participants))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"Number of unique participants: 283\"\n```\n\n\n:::\n\n```{.r .cell-code}\nn_friends <- n_distinct(FFH$H_FriendID_)\nprint(paste(\"Number of unique friends listed:\", n_friends))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"Number of unique friends listed: 1594\"\n```\n\n\n:::\n\n```{.r .cell-code}\nFFH %>%\n  ggplot(aes(x = H_closeFriend)) +\n  geom_histogram(binwidth = 1, fill = \"steelblue\", color = \"white\", boundary = 0) +\n  facet_wrap(~Time) +\n  labs(title = \"Histogram of Closeness by Timepoint\",\n       x = \"Closeness (1 = Not at all close, 5 = Extremely close)\",\n       y = \"Count\") +\n  theme_minimal() +\n  theme(panel.grid = element_blank())\n```\n\n::: {.cell-output-display}\n![](tut_index_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n\n```{.r .cell-code}\nlillie.test(FFH$H_closeFriend)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tLilliefors (Kolmogorov-Smirnov) normality test\n\ndata:  FFH$H_closeFriend\nD = 0.19051, p-value < 2.2e-16\n```\n\n\n:::\n:::\n\n\n\n**So, we have 288 participants and 1,617 unique friends listed. In the table, you'll see a breakdown of closeness at each time point. These histograms, plus a quick test of normality, show that our outcome is not normally distributed. But, it's worth making our model and then investigating once the model is set.**\n\n**Now that we know what we're working with, we can start to decipher a model to investigate our research question:**\n\nWhat is the effect of Time on Closeness to friends from home?\n\nBecause of the nested nature of this data, our biggest contender is a mixed linear regression.\n\nA mixed linear model (also called a multilevel or hierarchical linear model) is a type of regression that accounts for nested or grouped data.\n\nIn our case, closeness ratings are repeated over time within each friend, and each friend is nested within a participant. This violates the assumption of independence in traditional linear regression, because observations from the same person or the same friendship are likely to be more similar to each other than to those from others. A mixed linear regression is ideal here because it allows us to model both fixed effects (like time) and random effects (like variation across participants and friendships). This helps us better understand the average trends while also accounting for individual differences in how close someone feels to their friends in general.\n\nBut first, we need to check a few assumptions to make sure this is the right model for us.\n\n# Checking Assumptions\n\nLet's see that our outcome variables is roughly normally distributed.\n\nBefore fitting a mixed model, it’s good practice to check whether the **outcome variable** is approximately normally distributed. For larger samples, `lillie.test()` from the `nortest` package is a more appropriate option. Still, these tests are sensitive — so it’s just as important to visually inspect the data using a histogram or a Q-Q plot. In our case, the closeness variable is on a 1–5 ordinal scale and shows a skewed, multimodal distribution, especially with a spike at “1” due to our recoding. This outcome isn't normally distributed, which we expected. That’s okay: normality is more important for model **residuals**, which we’ll check after fitting the model.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhist(FFH$H_closeFriend)\n```\n\n::: {.cell-output-display}\n![](tut_index_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n\n```{.r .cell-code}\nhist(FFH$H_closeFriend[FFH$Time==\"Intake\"])\n```\n\n::: {.cell-output-display}\n![](tut_index_files/figure-html/unnamed-chunk-11-2.png){width=672}\n:::\n\n```{.r .cell-code}\nhist(FFH$H_closeFriend[FFH$Time==\"Fall\"])\n```\n\n::: {.cell-output-display}\n![](tut_index_files/figure-html/unnamed-chunk-11-3.png){width=672}\n:::\n\n```{.r .cell-code}\nhist(FFH$H_closeFriend[FFH$Time==\"Winter\"])\n```\n\n::: {.cell-output-display}\n![](tut_index_files/figure-html/unnamed-chunk-11-4.png){width=672}\n:::\n\n```{.r .cell-code}\nhist(FFH$H_closeFriend[FFH$Time==\"Spring\"])\n```\n\n::: {.cell-output-display}\n![](tut_index_files/figure-html/unnamed-chunk-11-5.png){width=672}\n:::\n:::\n\n\n\nWe'll see how this plays out.\n\nNext, we're going to decide how to structure our model and whether we want to include random intercepts, random slopes, or both.\n\n**Random Intercepts**\n\nA **random intercept** allows each group (e.g., each participant or each friend) to have their own baseline level of the outcome (e.g., closeness). This is a good place to start when your data includes repeated measures or clustering.\n\nIn our case, we’re measuring closeness to multiple friends over time, with friends nested within participants. So we could include:\n\n-   A random intercept for Participant ID, to account for differences in overall closeness across people\n\n-   A random intercept for Friend ID, to account for some friends being consistently rated higher or lower than others\n\nLet's make sure that it **makes sense** to have random intercept for these. We do this by looking at the variance in our outcome variable `H_closeFriend` within each of these levels.\n\nWe'll start with a random intercept for `ID`.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(lme4)\nmodel_participant <- lmer(H_closeFriend ~ 1 + (1 | ID), data = FFH)\n# Extract variance components from the model\nvar_components <- as.data.frame(VarCorr(model_participant))\n\n# Compute total variance\ntotal_variance <- sum(var_components$vcov)\n\n# Calculate proportion of variance at each level\nvar_components$proportion <- var_components$vcov / total_variance\n\n# Show proportions in a readable table\nvar_components[, c(\"grp\", \"vcov\", \"proportion\")]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n       grp      vcov proportion\n1       ID 0.5996095   0.257216\n2 Residual 1.7315418   0.742784\n```\n\n\n:::\n\n```{.r .cell-code}\n# For participant-level ICC (model_participant)\nicc <- 0.6069 / (0.6069 + 1.7330)  # ≈ 0.26\n```\n:::\n\n\n\nThere’s no strict cutoff for what counts as \"high\" random effect variance, but values that explain at least 10% of the total variance (or raise the ICC above 0.10) are generally worth modeling.\n\nThis model above shows that **participants differed in their average closeness**, with a random intercept variance of **0.6069**. The residual (within-person) variance was **1.7330**, suggesting that a lot of variability still exists within each participant across time or across friends. Within-person variance explains about **26% (ICC = .26)** percent of the variance.\n\nLet's see how that compares when we add a random intercept for within-friend differences.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_friendXparticipant <- lmer(H_closeFriend ~ 1 + (1|ID) + (1 | ID:H_FriendID_), data = FFH)\nsummary(model_friendXparticipant)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nLinear mixed model fit by REML ['lmerMod']\nFormula: H_closeFriend ~ 1 + (1 | ID) + (1 | ID:H_FriendID_)\n   Data: FFH\n\nREML criterion at convergence: 22138.8\n\nScaled residuals: \n     Min       1Q   Median       3Q      Max \n-2.43035 -0.73437  0.02939  0.68168  2.53314 \n\nRandom effects:\n Groups         Name        Variance Std.Dev.\n ID:H_FriendID_ (Intercept) 0.1285   0.3584  \n ID             (Intercept) 0.5802   0.7617  \n Residual                   1.6209   1.2731  \nNumber of obs: 6370, groups:  ID:H_FriendID_, 1594; ID, 283\n\nFixed effects:\n            Estimate Std. Error t value\n(Intercept)  3.03205    0.04928   61.53\n```\n\n\n:::\n\n```{.r .cell-code}\nicc_fXp <- 0.1251647 / (0.1251647+0.5880710+1.6252385)\n```\n:::\n\n\n\n**We can see from our ICC calculation that there are some friend-level differences – that even for the same participant, some friends are consistently closer than others. And yet, given that this explains only about 6% of the variance, we should think carefully about including this in our model. So, let's compare both.**\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\noptions(scipen=100)\nanova(model_participant, model_friendXparticipant)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nrefitting model(s) with ML (instead of REML)\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\nData: FFH\nModels:\nmodel_participant: H_closeFriend ~ 1 + (1 | ID)\nmodel_friendXparticipant: H_closeFriend ~ 1 + (1 | ID) + (1 | ID:H_FriendID_)\n                         npar   AIC   BIC logLik -2*log(L)  Chisq Df\nmodel_participant           3 22182 22202 -11088     22176          \nmodel_friendXparticipant    4 22143 22170 -11067     22135 40.993  1\n                              Pr(>Chisq)    \nmodel_participant                           \nmodel_friendXparticipant 0.0000000001528 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n\n\nMoving from 22511→22474 (AIC) and 22532→22501 (BIC) means the friend‐nested model fits better even after penalizing for the extra parameter.\n\nSo, even though the friend‐level ICC was “small,” the formal test shows it significantly improves the model. We should therefore keep the friend‐level random intercept.\n\n-   `(1 | ID)` lets each participant have their own average closeness.\n\n-   `(1 | ID:H_FriendID_)` lets each friend (nested within a participant) also have their own average closeness.\n\n**Now, let's see if we should add any random slopes.** A natural next step is to let the **effect of Time vary by participant**, since some people may drift apart faster or slower than others. We can do that by adding a random slope for Time at the ID level:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# random intercepts for friends, and random intercept + slope of Time for participants\ntime_slope <- lmer(\n  H_closeFriend ~ 1 +\n    (1 + Time | ID) +\n    (1 | ID:H_FriendID_),\n  data = FFH\n)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nboundary (singular) fit: see help('isSingular')\n```\n\n\n:::\n\n```{.r .cell-code}\nsummary(time_slope)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nLinear mixed model fit by REML ['lmerMod']\nFormula: H_closeFriend ~ 1 + (1 + Time | ID) + (1 | ID:H_FriendID_)\n   Data: FFH\n\nREML criterion at convergence: 17891.2\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.9401 -0.4188 -0.0023  0.4700  3.8316 \n\nRandom effects:\n Groups         Name        Variance Std.Dev. Corr          \n ID:H_FriendID_ (Intercept) 0.5194   0.7207                 \n ID             (Intercept) 0.0000   0.0000                 \n                TimeFall    2.6579   1.6303    NaN          \n                TimeWinter  3.0615   1.7497    NaN 0.76     \n                TimeSpring  3.8124   1.9525    NaN 0.70 0.84\n Residual                   0.4372   0.6612                 \nNumber of obs: 6370, groups:  ID:H_FriendID_, 1594; ID, 283\n\nFixed effects:\n            Estimate Std. Error t value\n(Intercept)  3.97154    0.02433   163.2\noptimizer (nloptwrap) convergence code: 0 (OK)\nboundary (singular) fit: see help('isSingular')\n```\n\n\n:::\n\n```{.r .cell-code}\nanova(model_participant, model_friendXparticipant, time_slope)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nrefitting model(s) with ML (instead of REML)\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\nData: FFH\nModels:\nmodel_participant: H_closeFriend ~ 1 + (1 | ID)\nmodel_friendXparticipant: H_closeFriend ~ 1 + (1 | ID) + (1 | ID:H_FriendID_)\ntime_slope: H_closeFriend ~ 1 + (1 + Time | ID) + (1 | ID:H_FriendID_)\n                         npar   AIC   BIC   logLik -2*log(L)    Chisq Df\nmodel_participant           3 22182 22202 -11087.8     22176            \nmodel_friendXparticipant    4 22143 22170 -11067.3     22135   40.993  1\ntime_slope                 13 17912 18000  -8942.8     17886 4248.999  9\n                                    Pr(>Chisq)    \nmodel_participant                                 \nmodel_friendXparticipant       0.0000000001528 ***\ntime_slope               < 0.00000000000000022 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n\n\nIn our likelihood ratio rest and AIC comparison, we see a huge AIC drop (22474→18011) and highly significant LRT; allowing each participant to have their own Time‐trend dramatically improves the model.\n\nTheoretically, this still makes sense. By adding a random slope for Time, we're still allowing each participant to have their own trajectory of closeness over the four waves—instead of forcing everyone to change at the same average rate.\n\n-   Without a time slope: we assume the effect of going from Intake→Fall→Winter→Spring is identical for every person. Any real heterogeneity in trajectories gets lumped into the residual and can bias our time estimate or understate uncertainty.\n\n-   ***With*** a time slope: each person’s change‐over‐time is modeled explicitly. We capture “fast drifters” vs. “stable stayers,” we properly propagate that extra uncertainty into our fixed‐effect test of Time.\n\n## Fit Model\n\nNow let's fit our model. Below, we model...\n\nThe effect of `Time` on closeness `H_closeFriend` with random effects.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(lmerTest)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\nAttaching package: 'lmerTest'\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nThe following object is masked from 'package:lme4':\n\n    lmer\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nThe following object is masked from 'package:stats':\n\n    step\n```\n\n\n:::\n\n```{.r .cell-code}\nmain_analysis <- lmer(\nH_closeFriend ~ Time +\n  (1 + Time | ID) +        # each participant has their own baseline closeness AND their own Time‐trend  \n  (1 | ID:H_FriendID_),    # each friendship (within participant) has its own baseline closeness\n  data = FFH)\nsummary(main_analysis)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: H_closeFriend ~ Time + (1 + Time | ID) + (1 | ID:H_FriendID_)\n   Data: FFH\n\nREML criterion at convergence: 17480\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-4.0237 -0.4102 -0.0027  0.4434  3.9172 \n\nRandom effects:\n Groups         Name        Variance Std.Dev. Corr             \n ID:H_FriendID_ (Intercept) 0.4267   0.6532                    \n ID             (Intercept) 0.2074   0.4554                    \n                TimeFall    1.7141   1.3093   -0.22            \n                TimeWinter  1.5641   1.2507   -0.39  0.61      \n                TimeSpring  1.5153   1.2310   -0.30  0.47  0.65\n Residual                   0.4244   0.6514                    \nNumber of obs: 6370, groups:  ID:H_FriendID_, 1594; ID, 283\n\nFixed effects:\n             Estimate Std. Error        df t value            Pr(>|t|)    \n(Intercept)   4.00413    0.03608 275.77176  110.99 <0.0000000000000002 ***\nTimeFall     -1.02991    0.08161 279.20311  -12.62 <0.0000000000000002 ***\nTimeWinter   -1.30645    0.07836 277.60357  -16.67 <0.0000000000000002 ***\nTimeSpring   -1.56769    0.07717 279.89139  -20.31 <0.0000000000000002 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n           (Intr) TimFll TmWntr\nTimeFall   -0.253              \nTimeWinter -0.378  0.596       \nTimeSpring -0.316  0.472  0.632\n```\n\n\n:::\n:::\n\n\n\n**We can see from this model that each time point is associated with a significant drop in closeness, even with our random effects.**\n\n## Visualize Model\n\n**Let's visualize the model to further our understanding.**\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(emmeans)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWelcome to emmeans.\nCaution: You lose important information if you filter this package's results.\nSee '? untidy'\n```\n\n\n:::\n\n```{.r .cell-code}\n# 1a. Get estimated marginal means\nemm <- emmeans(main_analysis, ~ Time, pbkrtest.limit = 6462)\n\n# 1b. Turn into a data frame\nemm_df <- as.data.frame(emm)\n\n# 1c. Plot\nmain_plot<- ggplot(emm_df, aes(x = Time, y = emmean)) +\n  geom_line(group = 1) +\n  geom_point(size = 3) +\n  geom_errorbar(aes(ymin = lower.CL, ymax = upper.CL), width = .1) +\n  labs(\n    title = \"Estimated Mean Closeness by Wave\",\n    y = \"Predicted Closeness (±95% CI)\"\n  ) +\n  ylim(1,5)+\n  theme_classic()\n\nprint(main_plot)\n```\n\n::: {.cell-output-display}\n![](tut_index_files/figure-html/unnamed-chunk-17-1.png){width=672}\n:::\n:::\n\n\n\n**Let's take a closer look at the random effects we've been modeling.**\n\nFor that participant, we can now see how closeness to each friend rises or falls over the four waves—making the friend‐level variation explicit.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# 1. Filter for one participant\npid <- \"211810\"\ndf_pid <- FFH %>% filter(ID == pid)\n\n# 2. Add model‐predicted closeness (including both random intercepts/slopes)\ndf_pid <- df_pid %>%\n  mutate(pred = predict(main_analysis,\n                        newdata = .,\n                        re.form = ~(1 + Time | ID) + (1 | ID:H_FriendID_)))\n\n# 3. Plot each friend’s trajectory\nggplot(df_pid, aes(x = Time, y = pred, group = H_FriendID_, color = H_FriendID_)) +\n  geom_line() +\n  geom_point() +\n  labs(title = paste0(\"Participant \", pid, \": \\nFriend‐level Closeness Trajectories\"),\n       y = \"Predicted Closeness\") +\n  theme_classic() +\n  theme(legend.position = \"none\")\n```\n\n::: {.cell-output-display}\n![](tut_index_files/figure-html/unnamed-chunk-18-1.png){width=672}\n:::\n:::\n\n\n\nWe can even take a look at 20 cases from our model to see how individual trajectories differ from the average trend. By randomly sampling 20 participants and plotting their fitted closeness over time (using their own intercepts and slopes), this “spaghetti” plot makes the heterogeneity in change visible—some people’s closeness remains high and stable, others decline sharply, and many show more gradual shifts. This visualization adds value by showing exactly what the random‐slope term captures: it turns a single fixed‐effect line into a cloud of subject‐specific lines, helping us judge whether the average Time effect truly represents our sample or masks important individual differences.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# 2a. pick 20 random IDs\nset.seed(42)\nids20 <- sample(unique(FFH$ID), 20)\n\n# 2b. augment data with fitted values\ndf20 <- FFH %>%\n  filter(ID %in% ids20) %>%\n  mutate(\n    pred = predict(main_analysis,\n                   newdata = .,    # same data\n                   re.form = ~(1 + Time | ID))  # include participant randoms\n  )\n\n# 2c. plot\nggplot(df20, aes(x = Time, y = pred, group = ID, color = ID)) +\n  geom_line() +\n  geom_point() +\n  labs(\n    title = \"Subject‐specific Closeness Trajectories\",\n    y = \"Fitted Closeness\"\n  ) +\n  theme_classic() +\n  theme(legend.position = \"none\")\n```\n\n::: {.cell-output-display}\n![](tut_index_files/figure-html/unnamed-chunk-19-1.png){width=672}\n:::\n:::\n\n\n\n**Amazing!**\n\n## Testing Model Validity Further\n\nLet's run a few more tests to be sure that our model is valid.\n\nRemember we had some abnormality as far as the normality of the distribution of our outcome variable. Let's see how this effects our model.\n\nWhat we see below is that in our normality test, the p-value \\< 2.2×10⁻²² is astronomically small, so we have to reject the null hypothesis of “residuals are normally distributed.”\n\n**But** with such a large sample (n ≈ 6,462), even tiny departures can give very low p-values. It’s best to:\n\n1.  **Inspect a Q-Q plot** of the residuals to judge practical importance, and...\n\n2.  Remember that mixed models are fairly robust to modest normality violations—especially with balanced designs and large samples.\n\nIn the QQ Plot below, we see that actually, our data follows the line of \"normality\" alright afterall, with a bit of heavier tails than a perfect normal—i.e. a few residuals are more extreme than you’d expect under strict normality.\n\nWith \\~6,500 observations, these mild deviations are common and usually not fatal for inference in a mixed model.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(nortest)\nlillie.test(residuals(main_analysis))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tLilliefors (Kolmogorov-Smirnov) normality test\n\ndata:  residuals(main_analysis)\nD = 0.061099, p-value < 0.00000000000000022\n```\n\n\n:::\n\n```{.r .cell-code}\n# extract residuals\nres <- residuals(main_analysis)\n\n# Q–Q plot\nqqnorm(residuals(main_analysis))\nqqline(residuals(main_analysis), col = \"blue\", lwd = 2)\n```\n\n::: {.cell-output-display}\n![](tut_index_files/figure-html/unnamed-chunk-20-1.png){width=672}\n:::\n:::\n\n\n\nIf that's the case – that we just have a few outliers influencing our model, let's take a look at the most influential obesrvations and see if our model changes as a result.\n\nWe see many\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# install.packages(\"performance\")\nlibrary(performance)\nlibrary(see)\nout <- check_outliers(main_analysis, \"zscore_robust\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nConverting missing values (`NA`) into regular values currently not\n  possible for variables of class `NULL`.\n```\n\n\n:::\n\n```{.r .cell-code}\nprint(out)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nOK: No outliers detected.\n- Based on the following method and threshold: zscore_robust (3.291).\n- For variable: (Whole model)\n```\n\n\n:::\n\n```{.r .cell-code}\ncheck_autocorrelation(main_analysis)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nWarning: Autocorrelated residuals detected (p < .001).\n```\n\n\n:::\n\n```{.r .cell-code}\ncheck_singularity(main_analysis)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] FALSE\n```\n\n\n:::\n\n```{.r .cell-code}\ncheck_model(main_analysis)\n```\n\n::: {.cell-output-display}\n![](tut_index_files/figure-html/unnamed-chunk-21-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#\n# linear mixed‐model\n# library(lme4)\n# mod_lm <- lmer(as.numeric(H_closeFriend) ~ Time + (1|ID) + (1|ID:H_FriendID_), data=FFH)\n# AIC(mod_lm); BIC(mod_lm)\n# \n# # ordinal mixed‐model -- can't do slopes so we removed sloeps from both models.??? \n# library(ordinal)\n# mod_ord <- clmm(as.factor(H_closeFriend)       \n#             ~ Time + (1|ID) + (1|ID:H_FriendID_), data=FFH, link=\"logit\")\n# AIC(mod_ord, mod_lm, main_analysis); BIC(mod_ord, mod_lm, main_analysis)\n# \n# theme_set(theme_classic(base_size = 6))\n# nominal_test(mod_ord)\n```\n:::\n\n::: {.cell}\n\n:::\n\n\n\n**Add in a moderator.**\n\n**Visualize.**\n\n**Compare.**\n\n**Conclusions and Wrap Up.**\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprint(\"hi\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"hi\"\n```\n\n\n:::\n:::\n",
    "supporting": [
      "tut_index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}